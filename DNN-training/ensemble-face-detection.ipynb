{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport tensorflow as tf # TensorFlow\nimport keras\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory # data processing\nfrom tensorflow.keras.layers import RandomFlip, RandomTranslation, RandomRotation, RandomZoom, RandomContrast, RandomCrop, Dense, Average, Flatten, Dropout # layers used in NN\nfrom keras.applications import xception, inception_resnet_v2, resnet_v2 # models used for transfer learning\nimport gc #garbage collection","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-17T22:28:38.369156Z","iopub.execute_input":"2022-01-17T22:28:38.369624Z","iopub.status.idle":"2022-01-17T22:29:34.226632Z","shell.execute_reply.started":"2022-01-17T22:28:38.369588Z","shell.execute_reply":"2022-01-17T22:29:34.225119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# General variables\n# seed for reproducible results (y, the first letter of my first name, in Ascii ;P )\nmy_seed = 121\n# the directory in which the data is\ndir = \"../input/glasses-data/glasses\"\n# the directory where the data output goes\nout_dir = \"./\"\n# directory of images with glasses\nglass_dir = dir + \"/glasses/\"\nno_glass_dir = dir + \"/no_glasses/\"\n# a bit bigger than final input to the model to augment the data a bit better\nimg_data_size = (512, 512)\nimg_size = (224, 224,3)\n# batch size\nbatch_size = 16\n# class weights, as the dataset is slightly imbalanced\nweights = {0:0.44,1:0.56}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# method that returns custom callbacks, according to your model name and \"base\" or \"tune\" (base training or finetuning)\ndef get_callbacks(mode, name):\n    if mode == \"base\":\n        return [keras.callbacks.ReduceLROnPlateau(patience=2), keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True), keras.callbacks.TensorBoard(log_dir=f'{out_dir}{name}-logs-base'), tf.keras.callbacks.ModelCheckpoint(filepath=f\"/{name}-best-base\", monitor='val_loss', save_best_only=True)]\n    else:\n        return [keras.callbacks.ReduceLROnPlateau(patience=1), keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True), keras.callbacks.TensorBoard(log_dir=f'{out_dir}{name}-logs-tune'), tf.keras.callbacks.ModelCheckpoint(filepath=f\"/{name}-best-tune\", monitor='val_loss', save_best_only=True)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use keras preprocessing fucntionalities and get dataset\ntrain = image_dataset_from_directory(directory=dir,  labels=\"inferred\", label_mode=\"binary\", \n                                     image_size = img_data_size,  seed=my_seed,\n                                     validation_split=0.2, subset=\"training\", batch_size=batch_size)\nvalidation = image_dataset_from_directory(directory=dir,  labels=\"inferred\", label_mode=\"binary\", \n                                          image_size = img_data_size,  seed=my_seed,\n                                          validation_split=0.2, subset=\"validation\", batch_size=batch_size)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function that returns a model of one of the models used for transfer learning (given the base model), removes code redundancy\ndef get_model(input_layer, preprocess, model):\n    data_pre = preprocess(input_layer)\n    name = model.name\n    model.trainable = False\n    base_model = model(data_pre)\n    flat = Flatten()(base_model)\n    drop1 = Dropout(rate=0.5, seed=my_seed)(flat)\n    dense1 = Dense(units=128, activation=\"relu\")(drop1)\n    drop2 = Dropout(rate=0.2, seed=my_seed)(dense1)\n    out = Dense(units=1, activation=\"sigmoid\")(drop2)\n    ret_model = keras.Model(input_tensor, out)\n    ret_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[\"accuracy\"])\n    print(\"start: base training \" + name)\n    ret_model.fit(train, epochs=20, verbose=2, validation_data=validation, shuffle=True, class_weight=weights, callbacks=get_callbacks(\"base\", model.name))\n    print(\"finished: base training \" + name)\n    # fine tuning\n    ret_model.trainable = True\n    ret_model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss=tf.keras.losses.BinaryCrossentropy(),metrics=[\"accuracy\"])\n    print(\"start: fine tuning \" + name)\n    ret_model.fit(train, epochs = 5, verbose=2, validation_data=validation,  shuffle=True, class_weight=weights, callbacks=get_callbacks(\"tune\", model.name))\n    print(\"finished: fine tuning \" + name)\n    # remove top two layers\n    ret_model = keras.Model(input_tensor, dense1)\n    # remove the last two layers from memory\n    del drop2\n    del out\n    gc.collect()\n    # make the model not trainable\n    ret_model.trainable = False\n    return ret_model, dense1","metadata":{"execution":{"iopub.status.busy":"2022-01-20T18:01:07.014317Z","iopub.execute_input":"2022-01-20T18:01:07.014923Z","iopub.status.idle":"2022-01-20T18:01:07.051834Z","shell.execute_reply.started":"2022-01-20T18:01:07.014796Z","shell.execute_reply":"2022-01-20T18:01:07.050701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize input layer(s)\ninput_tensor = keras.Input(shape=(512,512,3))\ndata_flip = RandomFlip(mode=\"horizontal\", seed=my_seed)(input_tensor)\ndata_trans = RandomTranslation(height_factor=0.1, width_factor=0.1, seed=my_seed)(data_flip)\ndata_rot = RandomRotation(factor=0.25, seed=my_seed)(data_trans)\ndata_zoom = RandomZoom(height_factor=0.1, width_factor=0.1)(data_rot)\ndata_contrast = RandomContrast(factor=0.3, seed=my_seed)(data_zoom)\ndata_pre = RandomCrop(height=224, width=224, seed=my_seed)(data_contrast)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the three base models \nxception_model, xception_layer = get_model(data_pre, xception.preprocess_input, xception.Xception(include_top=False, weights = \"imagenet\", input_shape=img_size))\ninception_resnet, inception_layer = get_model(data_pre, inception_resnet_v2.preprocess_input, inception_resnet_v2.InceptionResNetV2(include_top=False, weights = \"imagenet\", input_shape=img_size))\nresnet_model, resnet_layer = get_model(data_pre, resnet_v2.preprocess_input, resnet_v2.ResNet152V2(input_shape = img_size, include_top=False, weights = \"imagenet\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# garbage collection\ngc.collect()\n# create ensemble model \nconcat = tf.keras.layers.Concatenate()([xception_layer, inception_layer, resnet_layer])\ndrop1 = Dropout(rate=0.5, seed=my_seed)(concat)\ndense = Dense(units=128, activation=\"relu\")(drop1)\ndrop2 = Dropout(rate=0.2, seed=my_seed)(dense)\nout = Dense(units=1, activation=\"sigmoid\")(drop2)\nensemble = keras.Model(input_tensor, out)\n# compile the model\nensemble.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[\"accuracy\"])\nensemble.summary()\n# fit the model\nprint(\"start ensemble training\")\nensemble.fit(train, epochs=20, verbose=2, validation_data=validation, shuffle=True, class_weight=weights, callbacks=get_callbacks(\"base\", \"ensemble\"))\nprint(\"done ensemble training\")\nensemble.save(f\"{out_dir}final\")","metadata":{},"execution_count":null,"outputs":[]}]}